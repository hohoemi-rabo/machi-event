# 05. ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°å¼·åŒ–

## æ¦‚è¦
ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å‡¦ç†ã®ä¿¡é ¼æ€§ã‚’é«˜ã‚ã‚‹ãŸã‚ã€åŒ…æ‹¬çš„ãªã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°æ©Ÿèƒ½ã‚’å®Ÿè£…ã—ã¾ã™ã€‚

## ç›®çš„
- ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å¤±æ•—æ™‚ã®é©åˆ‡ãªå‡¦ç†
- ã‚¨ãƒ©ãƒ¼ã®å¯è¦–åŒ–ã¨é€šçŸ¥
- è‡ªå‹•ãƒªãƒˆãƒ©ã‚¤æ©Ÿèƒ½ã®å®Ÿè£…
- ã‚µã‚¤ãƒˆæ§‹é€ å¤‰æ›´ã®æ—©æœŸæ¤œçŸ¥

## ã‚¿ã‚¹ã‚¯

- [ ] ã‚¨ãƒ©ãƒ¼åˆ†é¡ã¨å®šç¾©
- [ ] ãƒªãƒˆãƒ©ã‚¤ãƒ­ã‚¸ãƒƒã‚¯å®Ÿè£…
- [ ] ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°è©³ç´°åŒ–
- [ ] ã‚¢ãƒ©ãƒ¼ãƒˆé€šçŸ¥æ©Ÿèƒ½ï¼ˆãƒ¡ãƒ¼ãƒ«/Slackï¼‰
- [ ] ã‚µã‚¤ãƒˆæ§‹é€ å¤‰æ›´æ¤œçŸ¥
- [ ] ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†å®Ÿè£…
- [ ] ã‚¨ãƒ©ãƒ¼ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰è¨­è¨ˆ

## ã‚¨ãƒ©ãƒ¼åˆ†é¡

### 1. ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¨ãƒ©ãƒ¼
- ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ
- æ¥ç¶šå¤±æ•—
- DNSè§£æ±ºå¤±æ•—

### 2. ãƒ‘ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼
- HTMLæ§‹é€ å¤‰æ›´
- ã‚»ãƒ¬ã‚¯ã‚¿ä¸ä¸€è‡´
- ãƒ‡ãƒ¼ã‚¿å½¢å¼ã‚¨ãƒ©ãƒ¼

### 3. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼
- æ¥ç¶šå¤±æ•—
- æ›¸ãè¾¼ã¿ã‚¨ãƒ©ãƒ¼
- åˆ¶ç´„é•å

### 4. æ¤œè¨¼ã‚¨ãƒ©ãƒ¼
- å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰æ¬ è½
- ä¸æ­£ãªæ—¥ä»˜å½¢å¼
- é‡è¤‡ãƒ‡ãƒ¼ã‚¿

## å®Ÿè£…

### ã‚¨ãƒ©ãƒ¼ã‚¯ãƒ©ã‚¹å®šç¾©
```typescript
class ScrapingError extends Error {
  constructor(
    message: string,
    public readonly siteName: string,
    public readonly errorType: ErrorType,
    public readonly retryable: boolean = false
  ) {
    super(message)
    this.name = 'ScrapingError'
  }
}

enum ErrorType {
  NETWORK = 'network',
  PARSING = 'parsing',
  DATABASE = 'database',
  VALIDATION = 'validation'
}
```

### ãƒªãƒˆãƒ©ã‚¤ãƒ­ã‚¸ãƒƒã‚¯
```typescript
async function retryWithBackoff<T>(
  fn: () => Promise<T>,
  maxRetries: number = 3,
  baseDelay: number = 1000
): Promise<T> {
  for (let i = 0; i < maxRetries; i++) {
    try {
      return await fn()
    } catch (error) {
      if (i === maxRetries - 1 || !isRetryable(error)) {
        throw error
      }

      const delay = baseDelay * Math.pow(2, i) // æŒ‡æ•°ãƒãƒƒã‚¯ã‚ªãƒ•
      await new Promise(resolve => setTimeout(resolve, delay))
    }
  }

  throw new Error('Max retries reached')
}

function isRetryable(error: Error): boolean {
  // ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¨ãƒ©ãƒ¼ã‚„ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã¯ãƒªãƒˆãƒ©ã‚¤å¯èƒ½
  return error instanceof ScrapingError && error.retryable
}
```

### ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°è¨˜éŒ²
```typescript
async function logDetailedError(
  supabase: SupabaseClient,
  error: ScrapingError
): Promise<void> {
  await supabase.from('scraping_logs').insert({
    site_name: error.siteName,
    status: 'failure',
    error_message: error.message,
    error_type: error.errorType,
    stack_trace: error.stack,
    events_count: 0,
    created_at: new Date().toISOString()
  })
}
```

### ã‚µã‚¤ãƒˆæ§‹é€ å¤‰æ›´æ¤œçŸ¥
```typescript
interface StructureCheck {
  siteName: string
  expectedMinEvents: number
  requiredFields: string[]
}

async function detectStructureChange(
  siteName: string,
  events: Event[]
): Promise<boolean> {
  // éå»ã®å¹³å‡å–å¾—æ•°ã‚’å–å¾—
  const { data: logs } = await supabase
    .from('scraping_logs')
    .select('events_count')
    .eq('site_name', siteName)
    .eq('status', 'success')
    .order('created_at', { ascending: false })
    .limit(10)

  if (!logs || logs.length === 0) return false

  const avgCount = logs.reduce((sum, log) => sum + log.events_count, 0) / logs.length

  // å–å¾—æ•°ãŒå¹³å‡ã®50%æœªæº€ãªã‚‰æ§‹é€ å¤‰æ›´ã®å¯èƒ½æ€§
  if (events.length < avgCount * 0.5) {
    await sendStructureChangeAlert(siteName, events.length, avgCount)
    return true
  }

  return false
}
```

### ã‚¢ãƒ©ãƒ¼ãƒˆé€šçŸ¥
```typescript
async function sendAlert(alert: Alert): Promise<void> {
  // ãƒ¡ãƒ¼ãƒ«é€šçŸ¥
  await sendEmail({
    to: Deno.env.get('ADMIN_EMAIL'),
    subject: `[machi-event] ${alert.type}: ${alert.siteName}`,
    body: alert.message
  })

  // Slacké€šçŸ¥ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
  if (Deno.env.get('SLACK_WEBHOOK_URL')) {
    await fetch(Deno.env.get('SLACK_WEBHOOK_URL')!, {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({
        text: `ğŸš¨ ${alert.siteName}: ${alert.message}`
      })
    })
  }
}
```

### ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°çµ±åˆ
```typescript
async function scrapeSiteWithErrorHandling(
  site: SiteConfig
): Promise<ScrapingResult> {
  try {
    // ãƒªãƒˆãƒ©ã‚¤ä»˜ãã§ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å®Ÿè¡Œ
    const events = await retryWithBackoff(
      () => scrapeSite(site),
      3,
      2000
    )

    // æ§‹é€ å¤‰æ›´ãƒã‚§ãƒƒã‚¯
    const structureChanged = await detectStructureChange(site.name, events)

    if (structureChanged) {
      return {
        success: false,
        siteName: site.name,
        eventsCount: 0,
        error: new ScrapingError(
          'Possible structure change detected',
          site.name,
          ErrorType.PARSING,
          false
        )
      }
    }

    // æ­£å¸¸çµ‚äº†
    return {
      success: true,
      siteName: site.name,
      eventsCount: events.length,
      events
    }

  } catch (error) {
    const scrapingError = error instanceof ScrapingError
      ? error
      : new ScrapingError(
          error.message,
          site.name,
          ErrorType.NETWORK,
          true
        )

    await logDetailedError(supabase, scrapingError)
    await sendAlert({
      type: 'ERROR',
      siteName: site.name,
      message: scrapingError.message
    })

    return {
      success: false,
      siteName: site.name,
      eventsCount: 0,
      error: scrapingError
    }
  }
}
```

## å—ã‘å…¥ã‚ŒåŸºæº–
- [ ] ã™ã¹ã¦ã®ã‚¨ãƒ©ãƒ¼ã‚¿ã‚¤ãƒ—ãŒé©åˆ‡ã«åˆ†é¡ã•ã‚Œã‚‹
- [ ] ãƒªãƒˆãƒ©ã‚¤ãƒ­ã‚¸ãƒƒã‚¯ãŒæ­£ã—ãå‹•ä½œã™ã‚‹
- [ ] ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ã«ååˆ†ãªæƒ…å ±ãŒè¨˜éŒ²ã•ã‚Œã‚‹
- [ ] ã‚¢ãƒ©ãƒ¼ãƒˆé€šçŸ¥ãŒå‹•ä½œã™ã‚‹
- [ ] ã‚µã‚¤ãƒˆæ§‹é€ å¤‰æ›´ãŒæ¤œçŸ¥ã•ã‚Œã‚‹
- [ ] ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿæ™‚ã‚‚ä»–ã‚µã‚¤ãƒˆã®ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã¯ç¶™ç¶šã™ã‚‹

## é–¢é€£ãƒ•ã‚¡ã‚¤ãƒ«
- `docs/03-scraping-core.md` - ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°åŸºç›¤
- `docs/04-scraping-sites.md` - 22ã‚µã‚¤ãƒˆå¯¾å¿œ
- `docs/17-operations.md` - é‹ç”¨ãƒ»ä¿å®ˆ

## ä¾å­˜é–¢ä¿‚
- `03-scraping-core.md` ã®å®Œäº†ãŒå¿…è¦
- `04-scraping-sites.md` ã¨ä¸¦è¡Œã—ã¦å®Ÿè£…å¯èƒ½

## æŠ€è¡“ãƒ¡ãƒ¢

### ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆè¨­å®š
```typescript
async function fetchWithTimeout(
  url: string,
  timeout: number = 10000
): Promise<Response> {
  const controller = new AbortController()
  const timeoutId = setTimeout(() => controller.abort(), timeout)

  try {
    const response = await fetch(url, { signal: controller.signal })
    return response
  } catch (error) {
    if (error.name === 'AbortError') {
      throw new ScrapingError(
        'Request timeout',
        url,
        ErrorType.NETWORK,
        true
      )
    }
    throw error
  } finally {
    clearTimeout(timeoutId)
  }
}
```

## å‚è€ƒ
- Error Handling Best Practices: https://deno.land/manual/examples/error_handling
- Exponential Backoff: https://en.wikipedia.org/wiki/Exponential_backoff
