import "jsr:@supabase/functions-js/edge-runtime.d.ts";
import { createClient } from 'https://esm.sh/@supabase/supabase-js@2'
import { isDuplicate, insertEvent, logScrapingResult, logDetailedError } from './utils.ts'
import { SITES, SiteConfig } from './sites-config.ts'
import { parseRssFeed } from './rss-parser.ts'
import { parseHtmlSite } from './html-parser.ts'
import { EventData } from './types.ts'
import { toScrapingError } from './error-types.ts'
import { retryWithBackoff } from './retry.ts'
import { detectStructureChange, createStructureChangeError } from './structure-checker.ts'
import { sendErrorAlert, sendStructureChangeAlert } from './alert.ts'

interface ScrapeAllResult {
  totalSites: number
  successfulSites: number
  failedSites: number
  totalEvents: number
  newEvents: number
  structureChanges: number
  errors: Array<{ site: string; error: string; errorType?: string }>
}

Deno.serve(async (req: Request) => {
  try {
    // Supabaseã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–ï¼ˆã‚µãƒ¼ãƒ“ã‚¹ãƒ­ãƒ¼ãƒ«ã‚­ãƒ¼ä½¿ç”¨ï¼‰
    const supabase = createClient(
      Deno.env.get('SUPABASE_URL') ?? '',
      Deno.env.get('SUPABASE_SERVICE_ROLE_KEY') ?? ''
    )

    console.log('Starting scraping for all sites...')

    // å…¨28ã‚µã‚¤ãƒˆã‚’ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°
    const result = await scrapeAllSites(supabase)

    return new Response(JSON.stringify(result), {
      headers: {
        'Content-Type': 'application/json',
        'Connection': 'keep-alive'
      }
    })
  } catch (error) {
    console.error('Edge Function error:', error)
    return new Response(JSON.stringify({
      success: false,
      error: error.message
    }), {
      status: 500,
      headers: {
        'Content-Type': 'application/json'
      }
    })
  }
})

/**
 * å…¨ã‚µã‚¤ãƒˆã‚’ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ï¼ˆä¸¦åˆ—å‡¦ç†ç‰ˆï¼‰
 */
async function scrapeAllSites(supabase: any): Promise<ScrapeAllResult> {
  const result: ScrapeAllResult = {
    totalSites: SITES.length,
    successfulSites: 0,
    failedSites: 0,
    totalEvents: 0,
    newEvents: 0,
    structureChanges: 0,
    errors: []
  }

  console.log(`\n=== Starting parallel scraping for ${SITES.length} sites ===`)

  // ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å‰ã«å…¨ã‚¤ãƒ™ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤ï¼ˆå…¨å‰Šé™¤â†’å†ç™»éŒ²æ–¹å¼ï¼‰
  console.log('ğŸ—‘ï¸ Deleting all existing events...')
  const { error: deleteError } = await supabase
    .from('events')
    .delete()
    .neq('id', '00000000-0000-0000-0000-000000000000') // å…¨ä»¶å‰Šé™¤ï¼ˆãƒ€ãƒŸãƒ¼æ¡ä»¶ï¼‰

  if (deleteError) {
    console.error('âŒ Failed to delete events:', deleteError)
  } else {
    console.log(`âœ… Deleted all existing events`)
  }

  // å…¨ã‚µã‚¤ãƒˆã‚’ä¸¦åˆ—å‡¦ç†
  const results = await Promise.allSettled(
    SITES.map(site => scrapeSingleSite(supabase, site))
  )

  // çµæœã‚’é›†è¨ˆ
  for (const siteResult of results) {
    if (siteResult.status === 'fulfilled') {
      const data = siteResult.value
      result.totalEvents += data.totalEvents
      result.newEvents += data.newEvents

      if (data.success) {
        result.successfulSites++
      } else {
        result.failedSites++
        if (data.structureChange) {
          result.structureChanges++
        }
        if (data.error) {
          result.errors.push(data.error)
        }
      }
    } else {
      // Promiseè‡ªä½“ãŒå¤±æ•—ã—ãŸå ´åˆï¼ˆé€šå¸¸ã¯ç™ºç”Ÿã—ãªã„ï¼‰
      result.failedSites++
      result.errors.push({
        site: 'Unknown',
        error: siteResult.reason?.message || 'Unknown error',
        errorType: 'unknown'
      })
    }
  }

  console.log(`\n=== Scraping Summary ===`)
  console.log(`Total sites: ${result.totalSites}`)
  console.log(`Successful: ${result.successfulSites}`)
  console.log(`Failed: ${result.failedSites}`)
  console.log(`Structure changes: ${result.structureChanges}`)
  console.log(`Total events: ${result.totalEvents}`)
  console.log(`New events: ${result.newEvents}`)

  return result
}

/**
 * å˜ä¸€ã‚µã‚¤ãƒˆã®ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å‡¦ç†
 */
async function scrapeSingleSite(supabase: any, site: SiteConfig) {
  console.log(`\n[${site.name}] Starting scraping...`)

  try {
    // ãƒªãƒˆãƒ©ã‚¤ä»˜ãã§ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å®Ÿè¡Œ
    const events = await retryWithBackoff(
      async () => {
        if (site.type === 'rss') {
          return await parseRssFeed(site.url, site.name, site.region)
        } else {
          return await parseHtmlSite(site)
        }
      },
      3,  // æœ€å¤§3å›ãƒªãƒˆãƒ©ã‚¤
      2000 // 2ç§’ã‹ã‚‰é–‹å§‹
    )

    console.log(`[${site.name}] Found ${events.length} events`)

    // ã‚µã‚¤ãƒˆæ§‹é€ å¤‰æ›´æ¤œçŸ¥
    const structureCheck = await detectStructureChange(supabase, site.name, events)

    if (structureCheck.changed) {
      console.warn(`[${site.name}] âš ï¸ Structure change detected: ${structureCheck.reason}`)

      // æ§‹é€ å¤‰æ›´ã‚¢ãƒ©ãƒ¼ãƒˆé€ä¿¡
      await sendStructureChangeAlert(site.name, structureCheck)

      // æ§‹é€ å¤‰æ›´ã‚¨ãƒ©ãƒ¼ã¨ã—ã¦ãƒ­ã‚°è¨˜éŒ²
      const structureError = createStructureChangeError(site.name, structureCheck)
      await logDetailedError(supabase, structureError)

      return {
        success: false,
        structureChange: true,
        totalEvents: events.length,
        newEvents: 0,
        error: {
          site: site.name,
          error: structureCheck.reason || 'Structure change detected',
          errorType: 'parsing'
        }
      }
    }

    // å„ã‚¤ãƒ™ãƒ³ãƒˆã‚’å‡¦ç†
    let insertedCount = 0
    for (const event of events) {
      try {
        // é‡è¤‡ãƒã‚§ãƒƒã‚¯
        const duplicate = await isDuplicate(supabase, event)
        if (duplicate) {
          continue
        }

        // ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«æŒ¿å…¥
        const inserted = await insertEvent(supabase, event)
        if (inserted) {
          insertedCount++
        }
      } catch (error) {
        console.error(`[${site.name}] Error processing event:`, error)
      }
    }

    // æˆåŠŸãƒ­ã‚°è¨˜éŒ²
    const status = events.length > 0 ? 'success' : 'partial'
    await logScrapingResult(
      supabase,
      site.name,
      status,
      insertedCount,
      events.length === 0 ? 'No events found' : undefined
    )

    console.log(`[${site.name}] âœ“ Success: ${insertedCount} new events added`)

    return {
      success: true,
      structureChange: false,
      totalEvents: events.length,
      newEvents: insertedCount,
      error: null
    }

  } catch (error) {
    console.error(`[${site.name}] âœ— Failed:`, error)

    // ã‚¨ãƒ©ãƒ¼ã‚’ScrapingErrorã«å¤‰æ›
    const scrapingError = toScrapingError(error, site.name)

    // è©³ç´°ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°è¨˜éŒ²
    await logDetailedError(supabase, scrapingError)

    // ã‚¨ãƒ©ãƒ¼ã‚¢ãƒ©ãƒ¼ãƒˆé€ä¿¡ï¼ˆcriticalãªã‚¨ãƒ©ãƒ¼ã®ã¿ï¼‰
    if (!scrapingError.isRetryable()) {
      await sendErrorAlert(scrapingError)
    }

    return {
      success: false,
      structureChange: false,
      totalEvents: 0,
      newEvents: 0,
      error: {
        site: site.name,
        error: scrapingError.message,
        errorType: scrapingError.errorType
      }
    }
  }
}
